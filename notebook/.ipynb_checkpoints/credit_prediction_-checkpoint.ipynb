{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a916e5-b7ad-4e92-a118-a189b278e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import optuna\n",
    "\n",
    "from giskard import Dataset, Model, scan, testing\n",
    "import pickle\n",
    "\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "\n",
    "import clickhouse_connect\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af346c89-40de-4503-90ee-8563280f7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SPARK_COMPAT_VERSION = os.getenv('SPARK_COMPAT_VERSION')\n",
    "SCALA_COMPAT_VERSION = os.getenv('SCALA_COMPAT_VERSION')\n",
    "CATBOOST_SPARK_VERSION = os.getenv('CATBOOST_SPARK_VERSION')\n",
    "CLICKHOUSE_HOST = os.getenv('CLICKHOUSE_HOST')\n",
    "CLICKHOUSE_PORT = os.getenv('CLICKHOUSE_PORT')\n",
    "CLICKHOUSE_USER = os.getenv('CLICKHOUSE_USER')\n",
    "CLICKHOUSE_PASSWORD = os.getenv('CLICKHOUSE_PASSWORD')\n",
    "ACCESS_KEY=os.getenv('MINIO_ACCESS_KEY')\n",
    "SECRET_KEY=os.getenv('MINIO_SECRET_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4611343e-78af-4c09-875b-a4d3ba88e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_TYPES = {\n",
    "    'age': 'category',\n",
    "    'sex': 'category',\n",
    "    'job': 'category',\n",
    "    'housing': 'category',\n",
    "    'credit_amount': 'numeric',\n",
    "    'duration': 'numeric'\n",
    "}\n",
    "\n",
    "TARGET_COLUMN_NAME = 'default'\n",
    "FEATURE_COLUMNS = [i for i in COLUMN_TYPES.keys()]\n",
    "FEATURE_TYPES = {i: COLUMN_TYPES[i] for i in COLUMN_TYPES if i != TARGET_COLUMN_NAME}\n",
    "\n",
    "COLUMNS_TO_SCALE = [key for key in COLUMN_TYPES.keys() if COLUMN_TYPES[key] == \"numeric\"]\n",
    "COLUMNS_TO_ENCODE = [key for key in COLUMN_TYPES.keys() if COLUMN_TYPES[key] == \"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99036d0f-8e52-48a9-9eab-e48bb79b52e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = clickhouse_connect.get_client(host = CLICKHOUSE_HOST, \n",
    "                                       port = CLICKHOUSE_PORT, \n",
    "                                       user = CLICKHOUSE_USER, \n",
    "                                       password = CLICKHOUSE_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3927e3ea-9338-4639-aa63-536ea9478789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 14:03:37,705 pid:211 Thread-3 (_track) urllib3.connectionpool WARNING  Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1006)'))': /engage\n"
     ]
    }
   ],
   "source": [
    "query = fr'''\n",
    "select {reduce(lambda a,b: a + ', ' + b, FEATURE_COLUMNS)}\n",
    "from credit.credit\n",
    "'''\n",
    "X = pd.DataFrame(client.query(query).named_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a93afd58-3155-4561-8ef9-69f31c2d2df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = fr'''\n",
    "select {TARGET_COLUMN_NAME}\n",
    "from credit.credit\n",
    "'''\n",
    "y = pd.DataFrame(client.query(query).named_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3279f01f-7a24-46f0-ad37-bf59f305329f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2649\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2646\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2648\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2649\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2305\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2302\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2309\u001b[0m     )\n\u001b[1;32m   2311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size = 0.25,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed2f34df-25df-4117-856f-2a9753e202fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05 12:02:03,235 pid:178 Thread-3 (_track) urllib3.connectionpool WARNING  Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1006)'))': /engage\n"
     ]
    }
   ],
   "source": [
    "numeric_transformer = Pipeline(steps = [\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps = [\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, COLUMNS_TO_SCALE),\n",
    "        (\"cat\", categorical_transformer, COLUMNS_TO_ENCODE)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ef5dc8-ce11-4059-b53e-324179d183d3",
   "metadata": {},
   "source": [
    "### Optimize hyperparams (optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea44e9-bd2a-403b-a53b-3391b3dcab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):    \n",
    "    # CatBoostClassifier hyperparams\n",
    "    param = {\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\n",
    "            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "        ),\n",
    "        \"used_ram_limit\": \"3gb\",\n",
    "    }\n",
    "\n",
    "    # model\n",
    "    estimator = CatBoostClassifier(**param, verbose=False)\n",
    "    \n",
    "    # pipelines\n",
    "    clf_pipeline = Pipeline(steps = [\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", estimator)\n",
    "])\n",
    "    # cross-validation accuracy counting\n",
    "    accuracy = cross_val_score(clf_pipeline, df[FEATURE_COLUMNS], df[TARGET_COLUMN_NAME], cv=10, scoring= 'accuracy').mean()\n",
    "    return accuracy\n",
    "\n",
    "#study = optuna.create_study(direction=\"maximize\", study_name=\"CBC-2023-01-14-14-30\", storage='sqlite:///db/CBC-2023-01-14-14-30.db')\n",
    "# study = optuna.create_study(direction=\"maximize\", study_name=f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}\")\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"credit_classifier\")\n",
    "\n",
    "# Hyperparams searching\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# best result is\n",
    "params = study.best_params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ba97f7-8bdd-48b3-b45a-31fc1e1ccea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboostclassifier = Pipeline(steps = [\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", CatBoostClassifier(**params, verbose=False))\n",
    "])\n",
    "catboostclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe02a42-0aeb-4bdf-993c-eb9ffb6d7539",
   "metadata": {},
   "source": [
    "## Wrap dataset with Giskard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1565001-06d6-460d-b5e2-7e114bf2e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.concat([X_test, y_test], axis = 1)\n",
    "giskard_dataset = Dataset(\n",
    "    df = raw_data,\n",
    "    target=TARGET_COLUMN_NAME,\n",
    "    name = \"German credit scoring dataset\",\n",
    "    cat_columns=COLUMNS_TO_ENCODE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7daf2c4-33de-4df9-bbdb-111d1725bc65",
   "metadata": {},
   "source": [
    "## Wrap model with Giskard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1fb196-bd6e-4385-bc32-49165cb2cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "giskard_model = Model(\n",
    "    model=catboostclassifier,\n",
    "    model_type=\"classification\",     # Either regression, classification or text_generation.\n",
    "    name=\"Chunk classification\",\n",
    "    classification_labels=catboostclassifier.classes_,  # Their order MUST be identical to the prediction_function's output order\n",
    "    feature_names=FEATURE_COLUMNS     # Default: all columns of your dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36044d8-cbe6-437e-9a9d-9d28e1f6aa3c",
   "metadata": {},
   "source": [
    "## Scan model with Giskard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c231a9-5af7-4a1a-9890-efe3e96e7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = scan(giskard_model, giskard_dataset, verbose=False)\n",
    "results.to_html(\"giskard_scan_result.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70fd3a0-c172-4a88-919a-aa3b2656c1b1",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2525a2-5b60-4346-9bc2-59e8564de9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(catboostclassifier, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7b143-5840-46e3-acb4-96baea5b1f40",
   "metadata": {},
   "source": [
    "# Minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c52214d5-82e8-4c73-812a-2c373f72c87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket credit-model already exists\n",
      "model.pkl successfully uploaded as object model.pkl to bucket credit-model\n"
     ]
    }
   ],
   "source": [
    "def s3_upload_model():\n",
    "    # Create a client with the MinIO server playground, its access key\n",
    "    # and secret key.\n",
    "    client = Minio(\"s3:9099\",\n",
    "        access_key=ACCESS_KEY,\n",
    "        secret_key=SECRET_KEY,\n",
    "        secure=False\n",
    "    )\n",
    "\n",
    "    # The file to upload, change this path if needed\n",
    "    source_file = \"model.pkl\"\n",
    "\n",
    "    # The destination bucket and filename on the MinIO server\n",
    "    bucket_name = \"credit-model\"\n",
    "    destination_file = \"model.pkl\"\n",
    "\n",
    "    # Make the bucket if it doesn't exist.\n",
    "    found = client.bucket_exists(bucket_name)\n",
    "    if not found:\n",
    "        client.make_bucket(bucket_name)\n",
    "        print(\"Created bucket\", bucket_name)\n",
    "    else:\n",
    "        print(\"Bucket\", bucket_name, \"already exists\")\n",
    "\n",
    "    # Upload the file, renaming it in the process\n",
    "    client.fput_object(\n",
    "        bucket_name, destination_file, source_file,\n",
    "    )\n",
    "    print(\n",
    "        source_file, \"successfully uploaded as object\",\n",
    "        destination_file, \"to bucket\", bucket_name,\n",
    "    )\n",
    "\n",
    "try:\n",
    "    s3_upload_model()\n",
    "except S3Error as exc:\n",
    "    print(\"error occurred.\", exc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
