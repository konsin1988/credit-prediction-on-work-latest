{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3a916e5-b7ad-4e92-a118-a189b278e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import optuna\n",
    "\n",
    "from giskard import Dataset, Model, scan, testing\n",
    "import pickle\n",
    "\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "import warnings\n",
    "\n",
    "# import clickhouse_connect\n",
    "import psycopg2\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import clickhouse_connect\n",
    "\n",
    "import mlflow \n",
    "import mlflow.catboost\n",
    "import mlflow.sklearn\n",
    "import mlflow.data\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26599f47-ec65-4763-a45c-6c8cf27ef447",
   "metadata": {},
   "source": [
    "# Env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af346c89-40de-4503-90ee-8563280f7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SPARK_COMPAT_VERSION = os.getenv('SPARK_COMPAT_VERSION')\n",
    "SCALA_COMPAT_VERSION = os.getenv('SCALA_COMPAT_VERSION')\n",
    "CATBOOST_SPARK_VERSION = os.getenv('CATBOOST_SPARK_VERSION')\n",
    "DB_HOST = os.getenv('DB_HOST')\n",
    "POSTGRESQL_PORT = os.getenv('POSTGRESQL_PORT')\n",
    "CLICKHOUSE_PORT = os.getenv('CLICKHOUSE_PORT')\n",
    "DB_USER = os.getenv('DB_USER')\n",
    "DB_PASSWORD = os.getenv('DB_PASSWORD')\n",
    "DB_NAME = os.getenv('DB_NAME')\n",
    "\n",
    "ACCESS_KEY=os.getenv('MINIO_ROOT_USER')\n",
    "SECRET_KEY=os.getenv('MINIO_ROOT_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590242f9-cf3b-4fb8-ba6d-2a9acf890467",
   "metadata": {},
   "source": [
    "# Set feature and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4611343e-78af-4c09-875b-a4d3ba88e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_TYPES = {\n",
    "    'age': 'category',\n",
    "    'sex': 'category',\n",
    "    'job': 'category',\n",
    "    'housing': 'category',\n",
    "    'credit_amount': 'numeric',\n",
    "    'duration': 'numeric'\n",
    "}\n",
    "\n",
    "TARGET_COLUMN_NAME = 'default'\n",
    "FEATURE_COLUMNS = [i for i in COLUMN_TYPES.keys()]\n",
    "FEATURE_TYPES = {i: COLUMN_TYPES[i] for i in COLUMN_TYPES if i != TARGET_COLUMN_NAME}\n",
    "\n",
    "COLUMNS_TO_SCALE = [key for key in COLUMN_TYPES.keys() if COLUMN_TYPES[key] == \"numeric\"]\n",
    "COLUMNS_TO_ENCODE = [key for key in COLUMN_TYPES.keys() if COLUMN_TYPES[key] == \"category\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df61e3a8-7dcc-4786-a4de-7b0617a3f600",
   "metadata": {},
   "source": [
    "# Connect to db (data) and get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99036d0f-8e52-48a9-9eab-e48bb79b52e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = clickhouse_connect.get_client(host = CLICKHOUSE_HOST, \n",
    "#                                        port = CLICKHOUSE_PORT, \n",
    "#                                        user = CLICKHOUSE_USER, \n",
    "#                                        password = CLICKHOUSE_PASSWORD)\n",
    "# query = fr'''\n",
    "# select {reduce(lambda a,b: a + ', ' + b, FEATURE_COLUMNS)}\n",
    "# from credit.credit\n",
    "# '''\n",
    "# X = pd.DataFrame(client.query(query).named_results())\n",
    "# X\n",
    "\n",
    "job_list = {\n",
    "    0: 'unskilled and non-resident', \n",
    "    1: 'unskilled and resident', \n",
    "    2: 'skilled', \n",
    "    3: 'highly skilled'\n",
    "}\n",
    "\n",
    "\n",
    "## Postgresql ==============================================\n",
    "conn = psycopg2.connect(dbname='credit',\n",
    "                                user=DB_USER,\n",
    "                                password=DB_PASSWORD,\n",
    "                                host='localhost',\n",
    "                                port=POSTGRESQL_PORT)\n",
    "cur = conn.cursor()\n",
    "cur.execute(f\"SELECT {reduce(lambda a,b: a + ', ' + b, FEATURE_COLUMNS)} FROM credit;\")\n",
    "X = (\n",
    "    pd\n",
    "    .DataFrame(cur.fetchall(), columns=FEATURE_COLUMNS)\n",
    "    .assign(job = lambda x: x['job'].apply(lambda x: job_list[x]))\n",
    ")\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(dbname='credit',\n",
    "                                user=DB_USER,\n",
    "                                password=DB_PASSWORD,\n",
    "                                host='localhost',\n",
    "                                port=POSTGRESQL_PORT)\n",
    "cur = conn.cursor()\n",
    "cur.execute(f'SELECT cr.\"{TARGET_COLUMN_NAME}\" FROM credit cr;')\n",
    "y = [x[0] for x in cur.fetchall()]\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "df = X.join(pd.DataFrame(y, columns = [TARGET_COLUMN_NAME]))\n",
    "#=================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd38048b-ed2b-47d1-86f5-0cdbc3043c10",
   "metadata": {},
   "source": [
    "# MLflow connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d8450d7-e83c-45b3-9259-3c4e16df79bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI http://localhost:5000/\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "mlflow.set_tracking_uri('http://localhost:5000/')\n",
    "print(\"URI\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a624fe-e5d0-4ebd-b898-8c011d975ba9",
   "metadata": {},
   "source": [
    "# MLflow experiment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3aa8557-d695-4e39-84cc-d285c3a04e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow/', creation_time=1747062720348, experiment_id='39', last_update_time=1747062720348, lifecycle_stage='active', name='credit_predict_01.05.2025', tags={}>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = f'credit_predict_{datetime.now().strftime('01.%m.%Y')}'\n",
    "try:\n",
    "    mlflow.create_experiment(experiment_name, artifact_location=f's3://mlflow')\n",
    "except:\n",
    "    pass\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0894caf9-1795-4e10-a5d4-d17d1da8dbc2",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed2f34df-25df-4117-856f-2a9753e202fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps = [\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps = [\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "# \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, COLUMNS_TO_SCALE),\n",
    "        (\"cat\", categorical_transformer, COLUMNS_TO_ENCODE)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3279f01f-7a24-46f0-ad37-bf59f305329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preproccessed = preprocessor.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size = 0.25,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ef5dc8-ce11-4059-b53e-324179d183d3",
   "metadata": {},
   "source": [
    "### Optimize hyperparams (optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9cea44e9-bd2a-403b-a53b-3391b3dcab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 19:13:30,391] A new study created in memory with name: params_opt_20250512-191330\n",
      "[I 2025-05-12 19:13:37,675] Trial 0 finished with value: 0.7129974285662909 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08594614671522907, 'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.7129974285662909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run run_12.05.2025_19:13:30 at: http://localhost:5000/#/experiments/39/runs/7789c9bad2e84405a1bde47b33b853f5\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 19:13:41,383] Trial 1 finished with value: 0.7239784694874515 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08479310773029916, 'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian'}. Best is trial 1 with value: 0.7239784694874515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run run_12.05.2025_19:13:37 at: http://localhost:5000/#/experiments/39/runs/1949d2b86d3a4c909509224817b849f7\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 19:13:44,253] Trial 2 finished with value: 0.7129884375393357 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09390296274221702, 'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian'}. Best is trial 1 with value: 0.7239784694874515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run run_12.05.2025_19:13:41 at: http://localhost:5000/#/experiments/39/runs/3d0301b067af46128c42c9b637eedf2a\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/12 19:15:45 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\D01D0~1.KON\\AppData\\Local\\Temp\\tmphkt8wgfl\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.6.1', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 1748.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run params_opt_12.05.2025_19:13 at: http://localhost:5000/#/experiments/39/runs/86b9f8d9746c4089ae513e57d386c41e\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/39\n"
     ]
    },
    {
     "ename": "S3UploadFailedError",
     "evalue": "Failed to upload C:\\Users\\D01D0~1.KON\\AppData\\Local\\Temp\\tmphkt8wgfl\\model\\conda.yaml to mlflow/86b9f8d9746c4089ae513e57d386c41e/artifacts/catboostclassifier/conda.yaml: An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\boto3\\s3\\transfer.py:372\u001b[39m, in \u001b[36mS3Transfer.upload_file\u001b[39m\u001b[34m(self, filename, bucket, key, callback, extra_args)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[32m    376\u001b[39m \u001b[38;5;66;03m# client error.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\s3transfer\\futures.py:103\u001b[39m, in \u001b[36mTransferFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[32m    102\u001b[39m     \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_coordinator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\s3transfer\\futures.py:264\u001b[39m, in \u001b[36mTransferCoordinator.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\s3transfer\\tasks.py:135\u001b[39m, in \u001b[36mTask.__call__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transfer_coordinator.done():\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\s3transfer\\tasks.py:158\u001b[39m, in \u001b[36mTask._execute_main\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m    156\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecuting task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with kwargs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs_to_display\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m return_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# If the task is the final task, then set the TransferFuture's\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# value to the return value from main().\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\s3transfer\\upload.py:796\u001b[39m, in \u001b[36mPutObjectTask._main\u001b[39m\u001b[34m(self, client, fileobj, bucket, key, extra_args)\u001b[39m\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m fileobj \u001b[38;5;28;01mas\u001b[39;00m body:\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m     \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\botocore\\client.py:569\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    568\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m569\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\botocore\\client.py:1023\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1022\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mClientError\u001b[39m: An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mS3UploadFailedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     66\u001b[39m mlflow.log_input(dataset)\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# mlflow.evaluate(data=df, model_type=\"classifier\", targets=TARGET_COLUMN_NAME, model=catboostclassifier)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43msklearn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msk_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcatboostclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m                          \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcatboostclassifier\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m                          \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m                          \u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_example\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m                         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# mlflow.sklearn.save_model(sk_model=catboostclassifier, \u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m#                            path='catboostclassifier',\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m#                           signature=signature,\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m#                           input_example=input_example\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m#                          )\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\sklearn\\__init__.py:413\u001b[39m, in \u001b[36mlog_model\u001b[39m\u001b[34m(sk_model, artifact_path, conda_env, code_paths, serialization_format, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS.format(package_name=\u001b[33m\"\u001b[39m\u001b[33mscikit-learn\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_model\u001b[39m(\n\u001b[32m    336\u001b[39m     sk_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     metadata=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    349\u001b[39m ):\n\u001b[32m    350\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[33;03m    Log a scikit-learn model as an MLflow artifact for the current run. Produces an MLflow Model\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[33;03m    containing the following flavors:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    411\u001b[39m \n\u001b[32m    412\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43msklearn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43msk_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43msk_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\models\\model.py:921\u001b[39m, in \u001b[36mModel.log\u001b[39m\u001b[34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, **kwargs)\u001b[39m\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m    919\u001b[39m         client.log_prompt(run_id, prompt)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtracking\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfluent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[38;5;66;03m# if the model_config kwarg is passed in, then log the model config as an params\u001b[39;00m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_config := kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mmodel_config\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:1219\u001b[39m, in \u001b[36mlog_artifacts\u001b[39m\u001b[34m(local_dir, artifact_path, run_id)\u001b[39m\n\u001b[32m   1185\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1186\u001b[39m \u001b[33;03mLog all the contents of a local directory as artifacts of the run. If no run is active,\u001b[39;00m\n\u001b[32m   1187\u001b[39m \u001b[33;03mthis method will create a new active run.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1216\u001b[39m \u001b[33;03m            mlflow.log_artifacts(tmp_dir, artifact_path=\"states\")\u001b[39;00m\n\u001b[32m   1217\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1218\u001b[39m run_id = run_id \u001b[38;5;129;01mor\u001b[39;00m _get_or_start_run().info.run_id\n\u001b[32m-> \u001b[39m\u001b[32m1219\u001b[39m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\tracking\\client.py:2428\u001b[39m, in \u001b[36mMlflowClient.log_artifacts\u001b[39m\u001b[34m(self, run_id, local_dir, artifact_path)\u001b[39m\n\u001b[32m   2381\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_artifacts\u001b[39m(\n\u001b[32m   2382\u001b[39m     \u001b[38;5;28mself\u001b[39m, run_id: \u001b[38;5;28mstr\u001b[39m, local_dir: \u001b[38;5;28mstr\u001b[39m, artifact_path: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[32m   2385\u001b[39m \n\u001b[32m   2386\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2426\u001b[39m \n\u001b[32m   2427\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2428\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:964\u001b[39m, in \u001b[36mTrackingServiceClient.log_artifacts\u001b[39m\u001b[34m(self, run_id, local_dir, artifact_path)\u001b[39m\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_artifacts\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id, local_dir, artifact_path=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    956\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[32m    957\u001b[39m \n\u001b[32m    958\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    962\u001b[39m \n\u001b[32m    963\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m964\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_artifact_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\store\\artifact\\s3_artifact_repo.py:194\u001b[39m, in \u001b[36mS3ArtifactRepository.log_artifacts\u001b[39m\u001b[34m(self, local_dir, artifact_path)\u001b[39m\n\u001b[32m    191\u001b[39m     upload_path = posixpath.join(dest_path, rel_path)\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m filenames:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_upload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[43ms3_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43ms3_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposixpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\store\\artifact\\s3_artifact_repo.py:169\u001b[39m, in \u001b[36mS3ArtifactRepository._upload_file\u001b[39m\u001b[34m(self, s3_client, local_file, bucket, key)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m environ_extra_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    168\u001b[39m     extra_args.update(environ_extra_args)\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[43ms3_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mExtraArgs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\boto3\\s3\\inject.py:145\u001b[39m, in \u001b[36mupload_file\u001b[39m\u001b[34m(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Upload a file to an S3 object.\u001b[39;00m\n\u001b[32m    111\u001b[39m \n\u001b[32m    112\u001b[39m \u001b[33;03mUsage::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    142\u001b[39m \u001b[33;03m    transfer.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\boto3\\s3\\transfer.py:378\u001b[39m, in \u001b[36mS3Transfer.upload_file\u001b[39m\u001b[34m(self, filename, bucket, key, callback, extra_args)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[32m    376\u001b[39m \u001b[38;5;66;03m# client error.\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m S3UploadFailedError(\n\u001b[32m    379\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to upload \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    380\u001b[39m             filename, \u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m.join([bucket, key]), e\n\u001b[32m    381\u001b[39m         )\n\u001b[32m    382\u001b[39m     )\n",
      "\u001b[31mS3UploadFailedError\u001b[39m: Failed to upload C:\\Users\\D01D0~1.KON\\AppData\\Local\\Temp\\tmphkt8wgfl\\model\\conda.yaml to mlflow/86b9f8d9746c4089ae513e57d386c41e/artifacts/catboostclassifier/conda.yaml: An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records."
     ]
    }
   ],
   "source": [
    "def objective(trial):    \n",
    "    # CatBoostClassifier hyperparams\n",
    "    params = {\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\n",
    "            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "        ),\n",
    "        \"used_ram_limit\": \"3gb\",\n",
    "    }\n",
    "    with mlflow.start_run(run_name = f'run_{datetime.now().strftime('%d.%m.%Y_%H:%M:%S')}', nested=True):\n",
    "        \n",
    "        # model\n",
    "        mlflow.log_params(params)\n",
    "        estimator = CatBoostClassifier(**params, verbose=False)\n",
    "        \n",
    "        accuracy = cross_val_score(estimator, X_preproccessed, y, cv=3, scoring= 'accuracy').mean()\n",
    "        mlflow.log_metric('Accuracy', accuracy) \n",
    "        return accuracy\n",
    "\n",
    "\n",
    "experiment_name = f'credit_predict_{datetime.now().strftime('01.%m.%Y')}'\n",
    "try:\n",
    "    mlflow.create_experiment(experiment_name, artifact_location=f's3://mlflow/artifacts_{datetime.now().strftime('%d.%m.%Y_%H:%M')}/')\n",
    "except:\n",
    "    pass\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run(run_name = f'params_opt_{datetime.now().strftime('%d.%m.%Y_%H:%M')}') as run:\n",
    "    study = optuna.create_study(direction=\"maximize\", study_name=f\"params_opt_{datetime.now().strftime('%Y%m%d-%H%M%S')}\")\n",
    "\n",
    "    # Hyperparams searching\n",
    "    study.optimize(objective, n_trials=3)\n",
    "    \n",
    "    # best result is\n",
    "    params = study.best_params\n",
    "\n",
    "    estimator = CatBoostClassifier(**params, verbose=False)  \n",
    "    catboostclassifier = Pipeline(steps = [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", estimator)\n",
    "    ])\n",
    "    # catboostclassifier = CatBoostClassifier(**params, verbose=False)\n",
    "    catboostclassifier.fit(X_train, y_train)\n",
    "    \n",
    "    pred_test = catboostclassifier.predict(X_test)\n",
    "    signature = infer_signature(X_test, pred_test)\n",
    "\n",
    "    \n",
    "    metrics = {'accuracy': accuracy_score(pred_test, y_test),\n",
    "                'precision': precision_score(pred_test, y_test),\n",
    "                'recall': recall_score(pred_test, y_test),\n",
    "                'f1': f1_score(pred_test, y_test),\n",
    "                'roc_auc': roc_auc_score(y_test, catboostclassifier.predict_proba(X_test)[:,1])\n",
    "              }\n",
    "\n",
    "    \n",
    "    input_example = X_train.iloc[[0], :]\n",
    "    mlflow.models.infer_signature(input_example, 0, params)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    dataset = mlflow.data.from_pandas(df, name='german_credit', targets='default')\n",
    "    mlflow.log_input(dataset)\n",
    "    # mlflow.evaluate(data=df, model_type=\"classifier\", targets=TARGET_COLUMN_NAME, model=catboostclassifier)\n",
    "\n",
    "    mlflow.sklearn.log_model(sk_model=catboostclassifier, \n",
    "                              artifact_path='catboostclassifier', \n",
    "                              signature=signature,\n",
    "                              input_example=input_example\n",
    "                             )\n",
    "    # mlflow.sklearn.save_model(sk_model=catboostclassifier, \n",
    "    #                            path='catboostclassifier',\n",
    "    #                           signature=signature,\n",
    "    #                           input_example=input_example\n",
    "    #                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0ba97f7-8bdd-48b3-b45a-31fc1e1ccea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/12 19:18:12 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\D01D0~1.KON\\AppData\\Local\\Temp\\tmpjhhwpjnf\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.6.1', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 1750.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run run 12.05.2025 19:16 at: http://localhost:5000/#/experiments/39/runs/6229ed93b28e4861b21200035c926729\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/39\n"
     ]
    },
    {
     "ename": "S3UploadFailedError",
     "evalue": "Failed to upload C:\\Users\\D01D0~1.KON\\AppData\\Local\\Temp\\tmpjhhwpjnf\\model\\conda.yaml to mlflow/6229ed93b28e4861b21200035c926729/artifacts/catboostclassifier/conda.yaml: An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\boto3\\s3\\transfer.py:372\u001b[39m, in \u001b[36mS3Transfer.upload_file\u001b[39m\u001b[34m(self, filename, bucket, key, callback, extra_args)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[32m    376\u001b[39m \u001b[38;5;66;03m# client error.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\s3transfer\\futures.py:103\u001b[39m, in \u001b[36mTransferFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[32m    102\u001b[39m     \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_coordinator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\s3transfer\\futures.py:264\u001b[39m, in \u001b[36mTransferCoordinator.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\s3transfer\\tasks.py:135\u001b[39m, in \u001b[36mTask.__call__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transfer_coordinator.done():\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\s3transfer\\tasks.py:158\u001b[39m, in \u001b[36mTask._execute_main\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m    156\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecuting task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with kwargs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs_to_display\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m return_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# If the task is the final task, then set the TransferFuture's\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# value to the return value from main().\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\s3transfer\\upload.py:796\u001b[39m, in \u001b[36mPutObjectTask._main\u001b[39m\u001b[34m(self, client, fileobj, bucket, key, extra_args)\u001b[39m\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m fileobj \u001b[38;5;28;01mas\u001b[39;00m body:\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m     \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\botocore\\client.py:569\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    568\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m569\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\botocore\\client.py:1023\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1022\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mClientError\u001b[39m: An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mS3UploadFailedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m mlflow.log_input(dataset)\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# mlflow.evaluate(data=df, model_type=\"classifier\", targets=TARGET_COLUMN_NAME, model=catboostclassifier)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43msklearn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatboostclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcatboostclassifier\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m                          \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m                          \u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_example\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m                         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# mlflow.sklearn.save_model(sk_model=catboostclassifier, \u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m#                            path='catboostclassifier',\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m#                           signature=signature,\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m#                           input_example=input_example\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m#                          )\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\sklearn\\__init__.py:413\u001b[39m, in \u001b[36mlog_model\u001b[39m\u001b[34m(sk_model, artifact_path, conda_env, code_paths, serialization_format, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS.format(package_name=\u001b[33m\"\u001b[39m\u001b[33mscikit-learn\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_model\u001b[39m(\n\u001b[32m    336\u001b[39m     sk_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     metadata=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    349\u001b[39m ):\n\u001b[32m    350\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[33;03m    Log a scikit-learn model as an MLflow artifact for the current run. Produces an MLflow Model\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[33;03m    containing the following flavors:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    411\u001b[39m \n\u001b[32m    412\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43msklearn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43msk_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43msk_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\models\\model.py:921\u001b[39m, in \u001b[36mModel.log\u001b[39m\u001b[34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, **kwargs)\u001b[39m\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m    919\u001b[39m         client.log_prompt(run_id, prompt)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtracking\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfluent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[38;5;66;03m# if the model_config kwarg is passed in, then log the model config as an params\u001b[39;00m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_config := kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mmodel_config\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:1219\u001b[39m, in \u001b[36mlog_artifacts\u001b[39m\u001b[34m(local_dir, artifact_path, run_id)\u001b[39m\n\u001b[32m   1185\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1186\u001b[39m \u001b[33;03mLog all the contents of a local directory as artifacts of the run. If no run is active,\u001b[39;00m\n\u001b[32m   1187\u001b[39m \u001b[33;03mthis method will create a new active run.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1216\u001b[39m \u001b[33;03m            mlflow.log_artifacts(tmp_dir, artifact_path=\"states\")\u001b[39;00m\n\u001b[32m   1217\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1218\u001b[39m run_id = run_id \u001b[38;5;129;01mor\u001b[39;00m _get_or_start_run().info.run_id\n\u001b[32m-> \u001b[39m\u001b[32m1219\u001b[39m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\tracking\\client.py:2428\u001b[39m, in \u001b[36mMlflowClient.log_artifacts\u001b[39m\u001b[34m(self, run_id, local_dir, artifact_path)\u001b[39m\n\u001b[32m   2381\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_artifacts\u001b[39m(\n\u001b[32m   2382\u001b[39m     \u001b[38;5;28mself\u001b[39m, run_id: \u001b[38;5;28mstr\u001b[39m, local_dir: \u001b[38;5;28mstr\u001b[39m, artifact_path: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[32m   2385\u001b[39m \n\u001b[32m   2386\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2426\u001b[39m \n\u001b[32m   2427\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2428\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:964\u001b[39m, in \u001b[36mTrackingServiceClient.log_artifacts\u001b[39m\u001b[34m(self, run_id, local_dir, artifact_path)\u001b[39m\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_artifacts\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id, local_dir, artifact_path=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    956\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[32m    957\u001b[39m \n\u001b[32m    958\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    962\u001b[39m \n\u001b[32m    963\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m964\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_artifact_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\store\\artifact\\s3_artifact_repo.py:194\u001b[39m, in \u001b[36mS3ArtifactRepository.log_artifacts\u001b[39m\u001b[34m(self, local_dir, artifact_path)\u001b[39m\n\u001b[32m    191\u001b[39m     upload_path = posixpath.join(dest_path, rel_path)\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m filenames:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_upload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[43ms3_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43ms3_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposixpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\store\\artifact\\s3_artifact_repo.py:169\u001b[39m, in \u001b[36mS3ArtifactRepository._upload_file\u001b[39m\u001b[34m(self, s3_client, local_file, bucket, key)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m environ_extra_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    168\u001b[39m     extra_args.update(environ_extra_args)\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[43ms3_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mExtraArgs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\boto3\\s3\\inject.py:145\u001b[39m, in \u001b[36mupload_file\u001b[39m\u001b[34m(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Upload a file to an S3 object.\u001b[39;00m\n\u001b[32m    111\u001b[39m \n\u001b[32m    112\u001b[39m \u001b[33;03mUsage::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    142\u001b[39m \u001b[33;03m    transfer.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\boto3\\s3\\transfer.py:378\u001b[39m, in \u001b[36mS3Transfer.upload_file\u001b[39m\u001b[34m(self, filename, bucket, key, callback, extra_args)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[32m    376\u001b[39m \u001b[38;5;66;03m# client error.\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m S3UploadFailedError(\n\u001b[32m    379\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to upload \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    380\u001b[39m             filename, \u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m.join([bucket, key]), e\n\u001b[32m    381\u001b[39m         )\n\u001b[32m    382\u001b[39m     )\n",
      "\u001b[31mS3UploadFailedError\u001b[39m: Failed to upload C:\\Users\\D01D0~1.KON\\AppData\\Local\\Temp\\tmpjhhwpjnf\\model\\conda.yaml to mlflow/6229ed93b28e4861b21200035c926729/artifacts/catboostclassifier/conda.yaml: An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records."
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='run ' + datetime.now().strftime('%d.%m.%Y %H:%M')) as run:\n",
    "    estimator = CatBoostClassifier(**params, verbose=False)\n",
    "    \n",
    "    catboostclassifier = Pipeline(steps = [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", estimator)\n",
    "    ])\n",
    "\n",
    "    \n",
    "    # catboostclassifier = CatBoostClassifier(**params, verbose=False)\n",
    "    catboostclassifier.fit(X_train, y_train)\n",
    "    \n",
    "    pred_test = catboostclassifier.predict(X_test)\n",
    "    signature = infer_signature(X_test, pred_test)\n",
    "\n",
    "    \n",
    "    metrics = {'accuracy': accuracy_score(pred_test, y_test),\n",
    "                'precision': precision_score(pred_test, y_test),\n",
    "                'recall': recall_score(pred_test, y_test),\n",
    "                'f1': f1_score(pred_test, y_test),\n",
    "                'roc_auc': roc_auc_score(y_test, catboostclassifier.predict_proba(X_test)[:,1])\n",
    "              }\n",
    "\n",
    "    \n",
    "    input_example = X_train.iloc[[0], :]\n",
    "    mlflow.models.infer_signature(input_example, 0, params)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    dataset = mlflow.data.from_pandas(df, name='german_credit', targets='default')\n",
    "    mlflow.log_input(dataset)\n",
    "    # mlflow.evaluate(data=df, model_type=\"classifier\", targets=TARGET_COLUMN_NAME, model=catboostclassifier)\n",
    "    \n",
    "    mlflow.sklearn.log_model(catboostclassifier, \n",
    "                              'catboostclassifier', \n",
    "                              signature=signature,\n",
    "                              input_example=input_example\n",
    "                             )\n",
    "    # mlflow.sklearn.save_model(sk_model=catboostclassifier, \n",
    "    #                            path='catboostclassifier',\n",
    "    #                           signature=signature,\n",
    "    #                           input_example=input_example\n",
    "    #                          )\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe02a42-0aeb-4bdf-993c-eb9ffb6d7539",
   "metadata": {},
   "source": [
    "## Wrap dataset with Giskard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1565001-06d6-460d-b5e2-7e114bf2e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.concat([X_test, y_test], axis = 1)\n",
    "giskard_dataset = Dataset(\n",
    "    df = raw_data,\n",
    "    target=TARGET_COLUMN_NAME,\n",
    "    name = \"German credit scoring dataset\",\n",
    "    cat_columns=COLUMNS_TO_ENCODE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7daf2c4-33de-4df9-bbdb-111d1725bc65",
   "metadata": {},
   "source": [
    "## Wrap model with Giskard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1fb196-bd6e-4385-bc32-49165cb2cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "giskard_model = Model(\n",
    "    model=catboostclassifier,\n",
    "    model_type=\"classification\",     # Either regression, classification or text_generation.\n",
    "    name=\"Chunk classification\",\n",
    "    classification_labels=catboostclassifier.classes_,  # Their order MUST be identical to the prediction_function's output order\n",
    "    feature_names=FEATURE_COLUMNS     # Default: all columns of your dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36044d8-cbe6-437e-9a9d-9d28e1f6aa3c",
   "metadata": {},
   "source": [
    "## Scan model with Giskard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c231a9-5af7-4a1a-9890-efe3e96e7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = scan(giskard_model, giskard_dataset, verbose=False)\n",
    "results.to_html(\"giskard_scan_result.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70fd3a0-c172-4a88-919a-aa3b2656c1b1",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed2525a2-5b60-4346-9bc2-59e8564de9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(catboostclassifier, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7b143-5840-46e3-acb4-96baea5b1f40",
   "metadata": {},
   "source": [
    "# Minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c52214d5-82e8-4c73-812a-2c373f72c87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created bucket credit-model-new-new\n",
      "model.pkl successfully uploaded as object model.pkl to bucket credit-model-new-new\n"
     ]
    }
   ],
   "source": [
    "def s3_upload_model():\n",
    "    # Create a client with the MinIO server playground, its access key\n",
    "    # and secret key.\n",
    "    client = Minio(\"localhost:9099\",\n",
    "        access_key=ACCESS_KEY,\n",
    "        secret_key=SECRET_KEY,\n",
    "        secure=False\n",
    "    )\n",
    "\n",
    "    # The file to upload, change this path if needed\n",
    "    source_file = \"model.pkl\"\n",
    "\n",
    "    # The destination bucket and filename on the MinIO server\n",
    "    bucket_name = \"credit-model-new-new\"\n",
    "    destination_file = \"model.pkl\"\n",
    "\n",
    "    # Make the bucket if it doesn't exist.\n",
    "    found = client.bucket_exists(bucket_name)\n",
    "    if not found:\n",
    "        client.make_bucket(bucket_name)\n",
    "        print(\"Created bucket\", bucket_name)\n",
    "    else:\n",
    "        print(\"Bucket\", bucket_name, \"already exists\")\n",
    "\n",
    "    # Upload the file, renaming it in the process\n",
    "    client.fput_object(\n",
    "        bucket_name, destination_file, source_file,\n",
    "    )\n",
    "    print(\n",
    "        source_file, \"successfully uploaded as object\",\n",
    "        destination_file, \"to bucket\", bucket_name,\n",
    "    )\n",
    "\n",
    "try:\n",
    "    s3_upload_model()\n",
    "except S3Error as exc:\n",
    "    print(\"error occurred.\", exc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
